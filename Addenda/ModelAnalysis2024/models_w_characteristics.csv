Model Provider,Model Name,Training Data Size (in trillions),Cut-off Date,Parameter Size (in billions),Release Date,Context Length (in thousands),Commercial,Multilingual,Multimodal,Base Model ,Instruction Tuning Data
01-ai,yi-34b-chat,3.0,,34.0,11/1/2023,4,0,1,0,,
01-ai,yi-1.5-6b-chat,3.6,,6.0,5/1/2024,32,0,1,0,,
01-ai,yi-1.5-9b-chat,3.6,,9.0,5/1/2024,4,0,1,0,,
01-ai,yi-1.5-34b-chat,3.6,,34.0,5/1/2024,32,0,1,0,,
Allenai,tulu-2-dpo-70b,,,70.0,11/1/2024,2,0,0,0,llama-2-70b-hf,"Ultrafeedback-binarized, tulu-v2-sft-mixture"
Anthropic,claude-2.1,,4/1/2023,137.0,11/1/2023,200,1,1,0,,
Anthropic,claude-3-haiku-20240307,,8/1/2023,,3/1/2024,200,1,1,1,,
Anthropic,claude-3-sonnet-20240229,,8/1/2023,,3/1/2024,200,1,1,1,,
Anthropic,claude-3-opus-20240229,,8/1/2023,2000.0,3/1/2024,200,1,1,1,,
cognitivecomputations,dolphin-2.5-mixtral-8x7b,,,45.0,12/1/2023,16,0,1,0,mixtral-8x7b-v0.1,"Magicoder-oss-instruct-75k, Magicoder-Evol-instruct-110k, openhermes"
Cohere,command-r,1.5,,35.0,3/1/2024,128,0,1,0,,
Cohere,command-r-plus,1.5,,104.0,4/1/2024,128,0,1,0,,
Google,gemma-1.1-7b-it,,,7.0,4/1/2024,8,0,0,0,gemma-7b,
Google,gemma-7b-it,6.0,,7.0,2/1/2024,8,0,0,0,,
Google,gemini-1.5-flash-latest,,11/1/2023,,4/1/2024,1048,1,1,1,,
Google,gemini-1.5-pro-latest,30.0,11/1/2023,1500.0,4/1/2024,1048,1,1,1,,
Google,gemini-1.0-pro,,4/1/2023,,2/1/2024,32,1,1,0,,
Meta,llama-3-8b-instruct,15.0,,8.0,4/1/2024,8,0,0,0,,
Meta,llama-3-70b-instruct,15.0,,70.0,4/1/2024,8,0,0,0,,
Meta,llama-2-70b-chat-hf,2.0,,70.0,7/1/2023,2,0,0,0,,
Mistralai,mistral-7b-instruct-v0.1,,,7.0,9/1/2023,8,0,0,0,,
Mistralai,mixtral-8x7b-instruct-v0.1,,,45.0,12/1/2023,32,0,1,0,,
Mistralai,mixtral-8x22b-instruct-v0.1,,,141.0,4/1/2024,64,0,1,0,,
Mistralai,mistral-medium-2312,,,,12/1/2023,32,1,1,0,,
Mistralai,mistral-large-2402,,,,2/1/2024,32,1,1,0,,
Mistralai,mistral-7b-instruct-v0.2,,,7.0,12/1/2023,32,0,0,0,,
Nexusflow,starling-lm-7b-beta,,,7.0,3/1/2024,8,0,0,0,openchat-3.5,Berkley-nest-Nectar
NousResearch,nous-hermes-2-mixtral-8x7b-sft,,,45.0,1/1/2024,32,0,1,0,mixtral-8x7b-v0.1,"1,000,000 entries of primarily GPT-4 generated data"
OpenAI,gpt-3.5-turbo-0125,,9/1/2021,175.0,1/1/2024,16,1,1,0,,
OpenAI,gpt-4-0613,,9/1/2021,1760.0,6/1/2023,8,1,1,0,,
OpenAI,gpt-4-1106-preview,,4/1/2023,1760.0,11/1/2023,128,1,1,1,,
OpenAI,gpt-4-0125-preview,,12/1/2023,1760.0,1/1/2024,128,1,1,1,,
OpenAI,gpt-4-turbo-2024-04-09,,12/1/2023,1760.0,5/1/2024,128,1,1,1,,
OpenAI,gpt-4o-2024-05-13,,10/1/2023,1760.0,5/1/2024,128,1,1,1,,
Openchat,openchat-3.5,,,7.0,10/1/2023,8,0,0,0,mistral-7b-v0.1,"Openchat sharegpt, Openorca with flan answers, Capybara. Goat, Glaive, Metamathqa, Mathinstruct, Openassistant"
Openchat,openchat-3.5-1210,,,7.0,12/1/2023,8,0,0,0,mistral-7b-v0.1,"Openchat sharegpt, Openorca with flan answers, Capybara decontaminated. Goat, Glaive, Metamathqa, Mathinstruct, Openassistant, Feedback collection"
Openchat,openchat-3.5-0106,,,7.0,1/1/2024,8,0,0,0,mistral-7b-v0.1,"Openchat sharegpt, Openorca with flan answers, Capybara decontaminated. Goat, Glaive, Metamathqa, Mathinstruct, Openassistant, Feedback collection"
Qwen,qwen1.5-0.5b-chat,2.2,,0.5,2/1/2024,32,0,1,0,,
Qwen,qwen1.5-1.8b-chat,2.2,,1.8,2/1/2024,32,0,1,0,,
Qwen,qwen1.5-7b-chat,2.4,,7.0,2/1/2024,32,0,1,0,,
Qwen,qwen1.5-14b-chat,3.0,,14.0,2/1/2024,32,0,1,0,,
Qwen,qwen1.5-32b-chat,3.0,,32.0,2/1/2024,32,0,1,0,,
Qwen,qwen1.5-72b-chat,3.0,,72.0,2/1/2024,32,0,1,0,,
Riid ,sheep-duck-llama-2-70b-v1.1,,,70.0,9/1/2023,2,0,0,0,llama-2-70b-hf,Orca and Alpaca style dataset
Wizardlmteam,wizardlm-70b-v1.0,,,70.0,8/1/2023,2,0,0,0,llama-2-70b-hf,Alpaca style dataset
