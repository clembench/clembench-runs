model,latency
Meta-Llama-3-8B-Instruct-GGUF-q8,0.18493384519931821
c4ai-command-r-plus-GGUF-q8,1.3738980355091392
Meta-Llama-3-70B-Instruct-GGUF-q8,0.9032176352420151
Meta-Llama-3-8B-Instruct-GGUF-q4,0.17574396574275958
c4ai-command-r-plus-GGUF-q4,1.0782782412593839
Meta-Llama-3-70B-Instruct-GGUF-q4,0.7134210776053239
