model,latency
c4ai-command-r-plus-GGUF-q8,1.3738980355091401
Meta-Llama-3-70B-Instruct-GGUF-q8,0.9032176352420122
Meta-Llama-3-70B-Instruct-GGUF-q4,0.7134210776053226
c4ai-command-r-plus-GGUF-q4,1.078278241259379
Meta-Llama-3-8B-Instruct-GGUF-q8,0.184933845199318
Meta-Llama-3-8B-Instruct-GGUF-q4,0.1757439657427601
